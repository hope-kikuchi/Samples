# Hazelcast
- https://hazelcast.org/

## Hello World
https://hazelcast.org/getting-started-with-hazelcast/

### やること
- 2つのノード(JVM)でインメモリ・データグリッドを作成する
- 最終的には、外部の Java アプリケーションからデータグリッドにアクセスする

### インストール
https://hazelcast.org/download/

```groovy
compile 'com.hazelcast:hazelcast:3.10.6'
```

## ノードを自動検出する仕組み
https://docs.hazelcast.org/docs/latest/manual/html-single/index.html#discovery-mechanisms

- 一度クラスタを組んだノード同士の通信は TCP/IP によって行われている
    - これは、ノードの発見方法とは関係しない
- 発見メカニズム (Discovery Mechanisms)
    - 単純な TCP による発見以外にも、 AWS 上でノードを見つける方法や Azure で見つける方法など、様々な方法が用意されている
- 基本は xml の設定ファイルでクラスタの情報を定義するっぽい
    - 設定がないときは、デフォルトでローカルホスの 5701, 5702 ポートに接続しようとするっぽい

## トポロジー
- クラスタの組み方が二種類存在する
- 組み込み(Embedded)と、クラサバ(Client/Server)
- 組み込み
    - 非同期・ハイパフォーマンス・大量タスクの実行に向いている
    - アプリケーションの中に Hazelcast を組み込む
    - データアクセスのレイテンシ(待ち時間)が減るのがメリット
- クラサバ
    - Hazelcast だけでデータサーバーを構築し、そこにアプリケーションがアクセスしにいく形式
    - クライアントになるアプリケーションは、個々に独立した存在になれる
        - 異なるアーキテクチャで構築できる
        - 個々のクライアントアプリケーションごとにスケールできる
    - Hazelcast のクライアント API を使ってアクセスする
        - Java, .NET, C++ は専用のクライアント API ライブラリが用意されている
        - REST API もある
    - メリット
        - Hazelcast だけに絞ったスケールが容易

## データパーティション
- shard (シャード)
    - 破片
    - 分割されたデータのことか？
- Hazelcast では、シャードのことを**パーティション**(Partitions)と呼んでいる
- パーティションとは、メモリセグメントのこと
    - 中に数百から数千のデータを格納できる
    - 実際どれくらい保存できるかは、実行環境のメモリ容量に依存する
- パーティションは複数の複製を持つことができる
    - それらは（複製のこと指している？）、クラスタの各メンバーに分配される
    - １つの複製が**プライマリ** (primary)となる
    - それ以外の複製は**バックアップ** (buckups)となる
    - プライマリを持つクラスタメンバのことを **プライマリオーナー** (primary owner) と呼ぶ
- データにアクセスすると、オーナーに対して透過的に対話が行われる
    - どれがオーナーかとかは意識することなく、クラスタ内からデータを引っ張り出せる、ってことかな
- デフォルトだと、１つ目に立ち上がったノードでは 271 のパーティションが作成される
    - この時点では、 271 のパーティションがすべてプライマリということになる
        - クラスタ化されていないので、複製がない状態ということ
- ２つ目のノードを立ち上げてクラスタが組まれると、２つ目のノードに１つ目のノードのパーティションがコピーされる
    - そして、半分の 135 のパーティションが、それぞれで重複しない形でプライマリパーティションになる
    - 残りの 136 は、バックアップとなる
- 3.6 で追加された Lite メンバーは、自分のパーティションを持っていない
    - 代わりに、クラスタ内の他のノードのパーティションを見ることができる
- どのようにしてデータがパーティションに分けられるのか
    - Hazelcast は、ハッシュアルゴリズムを使ってデータをパーティション内に配布する
    - オブジェクトの名前をハッシュ化してパーティションの数の剰余を取得する
        - オブジェクトの名前は、 HazelcastInstance から getList(String) とかしたときに引数で指定するやつ
        - 他にも Key というのもあるらしいが、よくわかってない
    - 剰余の結果がパーティションの ID になり、そのパーティションにデータが割り振られる
- パーティションテーブル
    - ノードを作成すると、内部でパーティションテーブルが作られる
    - テーブルには次の情報が格納されている
        - パーティションID
        - そのパーティションが、クラスタ内のどのノードに所属しているか
            - どれがオーナーか、ということ？
    - このテーブルの目的は、クラスタ内の全メンバーが、あるパーティションのオーナーがどのメンバーかを知ること
        - そのデータがどこにあるかがわかる
    - 最初に作成されたメンバーが、定期的にパーティションテーブルの情報を他のメンバーに送信している
        - 情報を受け取ったメンバーは、オーナーがどう変化したかを知ることができる
        - 最初に作成されたメンバーがクラスタから外れた場合は、次に古いメンバーが役割を引き継ぐ
    - パーティションテーブルの情報を送信する頻度は変更できる
        - `hazelcast.partition.table.send.interval`
        - デフォルトは 15 秒
- 再パーティション(Repartitioning)
    - 再パーティションとは、パーティションの所有者を再割り当てする処理のことを言う
    - 次のような場合に、再パーティションが行われる
        - メンバーがクラスタに参加した
        - メンバーがクラスタから離脱した
    - 最も古株のノードが持つパーティションテーブルが、新しいオーナーの情報で更新される
    - ただし、 Lite メンバーが参加・離脱しても再パーティションは行われない
        - Lite メンバーは自身のパーティションを持たないため
- パーティションの中にデータが入っているわけではないっぽい
    - 名前からパーティションを決定し、パーティションテーブルでオーナーを特定するというステップを踏むことで、効率的に分散されたデータにアクセスできるようになっている、ということか

## 設定ファイルを理解する
https://docs.hazelcast.org/docs/latest/manual/html-single/index.html#understanding-configuration

- Hazelcast の設定方法には以下の種類が存在する
    1. 宣言的な方法
    2. プログラミングによる方法
    3. Hazelcast のシステムプロパティを使用する方法
    4. Spring Context に含める方法
    5. 実行中のクラスで動的に設定を追加する方法(3.9 以上)
- 宣言的な方法
    - xml ファイルで設定を定義する
    - jar の中の `hazelcast-default.xml` がデフォルト値を定義した設定ファイル
    - `hazelcast-full-example.xml` は、全ての設定値を含むファイル
        - リファレンスドキュメントとして利用できる
- 設定ファイルの合成
    - `<import>` を使うことで、外部の設定ファイルをロードできる
- 設定ファイルをプログラムから読み込む
    - 設定ファイルの取得元ごとに `Config` クラスのサブクラスが用意されている
        - URL を指定して読み込む場合は `UrlXmlConfig`
        - ローカルファイルを読み込む場合は `FileSystemXmlConfig`
        - クラスパス上の設定ファイルを読み込む場合は `ClasspathXmlConfig`
- 動的な設定の追加
    - 普通、設定は静的で、一度インスタンスを生成すると変更することはできない
    - しかし、 3.9 からは一部の設定に限ってインスタンス生成後も設定を追加できるようになった
    - `Config` クラスで `add*Config()` という名前のメソッドが対象
    - `HazelcastInstance` の `getConfig()` で取得した `Config` インスタンスを使用するのが前提
    - 動的に追加する設定は、 `add*Config()` を呼び出す前に全て完了している必要がある
    - 動的に追加された設定は、クラスタ内の全てのノードに配布される
    - もしネットワークエラーなどの原因でクラスタ内のノードに配布できなかった場合
        - クラスタ内のメンバーの変更を検出するたびに内部的に再試行が行われる
        - `add*Config()` メソッドが例外を投げた場合は、ユーザ操作で再試行を行わなければならない
    - 設定ファイルの競合を制御する
        - 動的に追加した設定と同じ要素が、すでに静的な設定で指定されている場合
        - `ConfigurationException` がスローされる
        - 以前の動的な設定追加ものと同じ要素を、更に動的設定追加しようとした場合も `ConfigurationException` がスローされる
- 設定ファイルの検索
    - `Config` クラスを使わずに `HazelcastInstance` を生成した場合の挙動
        - `newHazelcastInstance()` を引数なしで使用した場合の話
    - デフォルトでは、次の順序で設定ファイルが検索される
        1. システムプロパティの `hazelcast.config` で指定されたファイル
            - `classpath:` で始めれば、クラスパス内のファイルを参照することも可能
        2. ワーキングディレクトリの `hazelcast.xml`
        3. クラスパス内の `hazelcast.xml`
        4. Hazelcast が内部に持つデフォルト値を設定した `hazelcast.xml`
- パターンマッチ
    - ワイルドカード
        - 分散データ構造の名前ではワイルドカードが使える
        - デフォルトでは、 `*` を使ったワイルドカードの指定がサポートされている
        - １つの名前の指定で `*` が使えるのは１回だけ
        - ある分散データ構造のインスタンス名が複数の設定とマッチした場合は、名前の指定が長い方が優先される
            - `mymap.customer.name` という名前のデータがあったとして、
            - `mymap.*` と `mymap.customer.*` という２つの設定が合った場合は、長い方の `mymap.customer.*` が優先される
    - 正規表現
        - パターンマッチのルールは任意のものに変更できる
        - 標準実装のなかに正規表現クラスがあるっぽいので、それに差し替えできそう
        
- 変数
    - システムプロパティに設定した値は、 `${名前}` という記法で設定ファイルに埋め込むことができる
    - `XmlConfigBuilder` に `setProperties(Properties)` を設定して `build()` で生成した設定ファイルを使えば、システムプロパティ以外で設定できる
    - `ClasspathXmlConfig` のコンストラクタは内部で `XmlConfigBuilder` を使っている
        - 引数に `Properties` を指定できるコンストラクタを使えば、内部で `XmlConfigBuilder` が利用されている
    - `FileSystemXmlConfig` とかも一緒
- 変数置換(Variable Replacers)
    - 設定ファイルを読み込むときに任意の値に置換する機能
    - パスワードのような機密情報などを扱うときに利用する
        - もちろん、それ以外の用途でも利用できる
    - `ConfigReplacter` インターフェースを実装して作成する
    - 標準で以下が用意されている
        - `EncryptionReplacer`
        - `PropertyReplacer`
    - 設定ファイル中に `$<PREFIX>{<VALUE>}` と指定しているときに、 `<PREFIX>` ごとに `Replacer` が適用され、 `<VALUE>` の値をもとに別の値に置換される
    - `EncryptionReplacer`
        - 暗号化された変数を置換する
        - プレフィックスは `ENC`
            - `$ENC{....}`
        - ファイル内の値にできるパスワードのために暗号化/復号化された秘密鍵は、MAC アドレスや実際のユーザデータのような環境固有の値から生成できる
        - 設定のためのプロパティ
            - `cipherAlgorithm`
                - 暗号化/復号化のためのアルゴリズム
                - デフォルトは AES
            - `keyLengthBits`
                - 生成される鍵のビット数
                - デフォルトは 128
            - `passwordFile`
                - 生成される暗号化パスワードの一部として利用するファイルのパス
                    - ファイルの内容をバイト配列で取得して Base64 でエンコードしたものをパスワードにするっぽい
                - 設定していない場合は利用されない
                - デフォルトは null
            - `passwordNetworkInterface`
                - パスワードの一部に使用する MAC アドレスを持つネットワークインターフェースの名前
                - 未設定の場合は利用されない
                - デフォルトは null
            - `passwordUserProperties`
                - `user.home` と `user.name` のシステムプロパティを使用してパスワードを生成するかどうか
                - デフォルトは true
            - `passwordFile`, `passwordNetworkInterface`, `passwordUserProperties` は、最低でも１つは設定（null でない or true）されている必要がある
            - `saltLengthBytes`
                - ランダムソルトのバイト数
                - デフォルトは 8 byte
            - `secretKeyAlgorithm`
                - 秘密鍵のアルゴリズム
                    - `SecretKeySpec` のコンストラクタの第二引数で渡す値
                - デフォルトが AES
            - `secretKeyFactoryAlgorithm`
                - パスワードから秘密鍵を生成するときのアルゴリズム
                    - `SecretKeyFactory.getInstance()` に渡す値
                - デフォルトは `PBKDF2WithHmacSHA256`
            - `securityProvider`
                - 秘密鍵のファクトリと暗号を見つけるための Java Security Provider の名前
                - デフォルトは null
        - `EncryptionReplacer` の `main()` 関数に暗号化したい引数を渡して実行すると、所定のフォーマットで暗号化された文字列が標準出力に出力される
            - 例：`$ENC{L6xyXa0XvK8=:531:OcTxoUoPYzQc+ZQop8IApA==}`
        - これを設定ファイルの任意の値に埋め込む
        - `<config-replacers>` で `com.hazelcast.config.replacer.EncryptionReplacer` を指定して設定ファイルを読み込む
        - すると、暗号化された値を `Config` から取得したときの値が復号化した状態で取得できる
    - `PropertyReplacer`
        - `${key}` と指定すると、 `key` という名前のシステムプロパティに置き換える
        - この `Replacer` は明示的な設定が不要で、デフォルトで動作する
        - プレフィックスは空文字
            - `${...}`
    - カスタムの Replacer
        - `ConfigReplacer` インターフェースを実装して作成する
        - `init(Properties)`
            - 最初に１回だけ呼ばれるメソッド
            - 引数の `Properties` は、設定ファイルの `<replacer>` 内の `<properties>` で指定している値が渡される
        - `getPrefix()`
            - カスタム Replacer のプレフィックスを返す
        - `getReplacement(String)`
            - 設定ファイルから取得されたマスク値が引数に渡されるので、置換後の値を返す

## 5. クラスタのセットアップ
https://docs.hazelcast.org/docs/latest/manual/html-single/index.html#setting-up-clusters

- 発見の仕組み
    - Hazelcast は自動的にクラスタに参加する仕組みを持つ
    - クラスタに参加するためのメカニズムは複数存在する
    - クラスタに参加したあとは、発見のメカニズムに関係なく TCP/IP で通信が行われる
    - TCP
        - 設定ファイルに以下を記述する必要がある
            - 全てのメンバーのホスト名かそのサブセット
            - メンバーの IP アドレス
        - クラスタ内の全てのメンバーを記述する必要はないが、新規にクラスタに参加するときには最低１つはアクティブである必要がある
        - TCP/IP を使用するには、以下のように設定を変更する
            - `network.join.multicast` の `enabled` 属性に `false` を設定する
            - `network.join.tcp-ip` の `enabled` 属性を `true` にする
            - `tcp-ip` の下にクラスタメンバの情報を記述する
                - `<member>` タグで記述
                    - ホスト名や IP アドレスを記述できる
                    - `192.168.1.0-7` のように範囲指定の記述が可能
                    - `192.168.1.1:5799` のようにポートの指定も可能
                        - ポートを指定していない場合は、 `5701` から順番にトライする
                        - おそらく、 `network.port` で指定した情報でトライのポート範囲が決まる
                - `<members>` タグなら、カンマ区切りで複数記述することも可能
            - ポートの指定がない場合、
    - Multicast
        - デフォルトで true ？
        - 本番環境での利用は推奨されないらしい
        - UDP を使うため接続が壊れることがある
        - 他のメカニズムのほうが確実
        - `MulticastService` というクラスで `MulticastSocket` を作っている
        - 
- クラスタのグループを作る
    - `<group>` タグを使うことで、クラスタのグループを作ることができる
    - グループは名前をつけて分けることができる
    - プログラムからグループを宣言することも可能
    - １つの JVM の上で、複数の HazelcastInstance を起動できる
        - それぞれ別々のグループで起動できる
        - 同じグループでも起動できる
    - 3.8 以前であれば、 `<password>` も合わせて設定する必要があった
        - 3.8 からはなくても良くなった
- パーティショングループの設定
    - データはパーティションに割り振られる
    - デフォルトでは、 Hazelcast は全てのパーティションを平等に扱う
    - しかし、もしあるメンバーが同じ JVM 上で動いていたり、物理的に同じ筐体の上で動いていた場合、物理的に異なるメンバーに割り振るように制御したくなるかもしれない
    - また、メンバーごとにマシン性能が異なるような場合は、パーティションの分割数なども同じにしたくないかもしれない
    - そういうときのために、パーティションのグループを作ることができるようになっている
    - グループ単位で、パーティションの数を設定できる
    - HOST_AWARE
        - IP アドレスでグループ化する
        - 同じネットワークインターフェースで公開しているインスタンスは、同じグループになる
        - 物理的にサーバーがクラッシュしたときに、データが失われるのを避けることができる
            - ホスト内のパーティションのレプリカは、必ず別のホストに存在するため
            - ただし、単一の筐体に複数のネットワークインターフェースが存在する場合は、この話は成り立たない
        - 設定
            - `<partition-group enabled="true" group-type="HOST_AWARE" />`
    - CUSTOM
        - 任意のネットワークインターフェースでグループを構成できる
        - IP アドレスにはワイルドカード (`*`) の指定も可能
            - `10.10.0.*`
        - 任意の IP アドレスを指定したラック構成などを作れる
    - PER_MEMBER
        - クラスタ内のメンバーごとにパーティショングループを作る
        - つまり、全てのメンバーが、それぞれ別のグループということになる
        - これは、 Hazelcast のデフォルト動作になる
            - `<partition-group>` 自体はデフォルト `enabled="false"` になってる
            - `true` にした場合のデフォルト構成ということか？
        - メンバーがそれぞれ異なるホストで動く場合は、良い冗長性を保てる
        - メンバーが同じホスト内で動作するのであれば、良い選択ではない
    - ZONE_AWARE
        - AWS や Azure のようなクラウドサービスを使っている場合の指定
        - それぞれの Discovery Service プラグインで設定する zone の情報をもとにグループが作られる
        - つまり、 zone ごとにパーティショングループが作られる
    - SPI
        - `AbstractDiscoveryStrategy` を継承して自力で実装する
- ログ設定
    - デフォルトで JDK のロガーをサポート
    - 一般的なロギングライブラリのアダプターをサポートしている
    - `hazelcast.logging.type` プロパティで指定できる
        - JDK (default)
        - log4j
        - log4j2
        - slf4j
        - none (ログなし)
    - プロパティでロギングライブラリを指定して、対象の jar を依存関係に入れれば自動的にそのロギングライブラリを使用するようになる
- 他のネットワーク設定
    - どれも `<network>` の下で設定する
    - 公開アドレス
        - `<public-address>` で設定
        - メンバーの公開アドレスを上書きする
        - デフォルトはソケットのアドレス
        - NAT (Network Address Translation) の背後で動く２つのメンバー間で通信する場合、そのままだと連携ができない
            - デフォルトだとプライベートアドレスが公開アドレスになってしまう
            - しかし、 NAT 経由で連携する他のメンバーは、こちらのグローバル IP アドレスと連携しようとする
        - 疑問
            - `<public-address>` はどういうタイミングで利用している？
            - 相手の IP アドレスの指定は、 `<member>` でやるのでは？
            - 自分自身の公開アドレスを設定しておく理由がいまいち分からない
    - ポート
        - `<port>`
        - TCP のポート設定
        - デフォルトは `5701`
        - `<port>` で指定したポートが既に使用されている場合は、 `auto-increment` に `true` が設定されていれば、 `port-count` の数だけポート番号をインクリメントしながら空いているポートを探す
        - `port-count` のデフォルトは `100`
        - この数は、同じマシン上で起動できるインスタンスの上限になる
        - `auto-increment` が `false` なら、空いているポートの自動検索は行われなくなる
    - 送信ポート
        - 送信に使用するポートは、デフォルトではシステム(OS)が選択した一時的なポートを使用する
        - セキュリティポリシーやファイアーウォールの設定で送信ポートを制限する必要がある場合は、 `<outbound-ports>` で設定する
        - `<ports>` を複数記述可能
        - `<ports>` の中では、カンマ区切りで複数ポートを指定したり、 `30000-35000` の用にハイフン区切りで範囲指定が可能
        - `0` または `*` を設定すると、デフォルトのシステムが選択したポートを使用する
    - アドレスの再使用
        - クラスタメンバーをシャットダウンすると、そのサーバーポートは数分の間 `TIME_WAIT` 状態になる
        - この状態だと、再度インスタンスを立ち上げても、そのポートは再利用されない
        - `<reuse-address>` に `true` を指定していると、 `TIME_WAIT` 状態であったとしてそのポートを再利用するようになる
    - 参加
        - `<join>` の下では、クラスタメンバーの発見方法を定義する
    - ネットワークインターフェース
        - Hazelcast が使用するネットワークインターフェースを指定できる
        - `<interfaces>` で指定する
        - 子要素に `<interface>` を指定する
            - 複数指定可能
        - 単純な IP アドレスだけでなく、 `*` によるワイルドカードや `-` による範囲指定も可能
            - `<interface>10.3.16.*</interface>`
            - `<interface>10.3.16.3-10</interface>`
    - IPv6
        - IP アドレスを指定する場所では、 IPv6 形式の指定も可能になっている
        - ただし、現在は `<join>` の設定でのみ、ワイルドカードの指定ができない
        - `<interface>` での設定であれば、ワイルドカードの指定が可能
        - なんか JVM のシステムプロパティで IPv6 を使うように指定が必要？
    - Member Address Provider SPI
        - AWS 上で Docker を使ってデプロイするようなケースだと、さらに複雑な公開アドレスの設定などが必要になるっぽい？
        - `MemberAddressProvider` インターフェースを実装したクラスを作ることで、プログラムから設定できる
- 故障検出の設定
    - 故障検出は、クラスタのメンバが到達不能またはクラッシュしたかを決定する責務を持つ
    - もっとも重要な問題は、メンバーの応答が単に遅いだけなのか、それとも本当にクラッシュしているのかを区別すること
    - 有名な FLP Result という論文によると、非同期で連携するシステムについてそれを区別することはできないらしい
    - この限界への回避策は、信頼できない故障検出を使うこと
    - 信頼できない故障検出では、メンバーが他のメンバーが故障しているのではないかと疑うことができる
    - 故障しているかどうかは、生存の基準をもとに行うが、これはある程度の確率で誤った判断をすることがある
    - Hazelcast は、２つの検出器を持っている
        - Deadline Failure Detector
        - Phi Accrual Failure Detector
    - 3.9.1 からはもう１つ検出器が追加された
        - Ping Failure Detector
            - OSI 第３層（ネットワークレイヤ）で故障を検出する
            - デフォルトは無効になっている
    - どの検出器を使うかは、 `hazelcast.heartbeat.failuredetector.type` プロパティで指定する
        - `deadline`
        - `phi-accrual`
    - Deadline Failure Detector
        - heartbeats のタイムアウトで検出する
        - タイムアウトが発生すると、そのメンバーはクラッシュした疑いがかけられる
        - ２つの設定値
            - `hazelcast.heartbeat.interval.seconds`
                - heartbeats の間隔
            - `hazelcast.max.no.heartbeat.seconds`
                - タイムアウト時間
    - Phi Accrual Failure Detector
        - sliding window 内のハートビートのインターバルの痕跡を残し、サンプリングした時間の平均と分散を測定し、疑いレベル（Phi）を計算する
            - sliding window
            - https://ja.wikipedia.org/wiki/%E3%82%B9%E3%83%A9%E3%82%A4%E3%83%87%E3%82%A3%E3%83%B3%E3%82%B0%E3%82%A6%E3%82%A3%E3%83%B3%E3%83%89%E3%82%A6
            - 通信高速化のフロー制御
            - あらかじめ決められた数の枠を設けておき、枠が空いていれば受信側からの応答を待たずに次々とデータを送信することで、全体的な通信時間を短縮する手法
        - 最後のハートビートからの時間が長くなれば、 phi も大きくなっていく
        - `hazelcast.heartbeat.interval.seconds` と `hazelcast.max.no.heartbeat.seconds` は、 Phi Accrual Failure Detector でも利用可能
            - `hazelcast.max.no.heartbeat.seconds` については、 Deadline よりもさらに小さい値にできる
            - ネットワークに適応しているらしいけど、意味がわからない
        - `hazelcast.heartbeat.phiaccrual.failuredetector.threshold`
            - 疑うかどうかを決める phi の閾値
            - phi の値がこの閾値を超えた場合、そのメンバーは到達不能になったものとして疑われる
            - 小さい値を設定した場合、クラッシュしたメンバーを迅速に検出できるようになる
            - しかし、その分誤検知も発生しやすくなる
            - 大きい値を設定した場合は、その逆で誤検知は減るが本当にクラッシュしたメンバーの検出が遅れる
            - `phi = 1` の場合、誤検知率は 10% ほど
            - `phi = 2` の場合、誤検知率は 1% ほど
            - `phi = 3` の場合、誤検知率は 0.1% ほど
            - デフォルトの閾値は `10`
        - `hazelcast.heartbeat.phiaccrual.failuredetector.sample.size`
            - 記録するサンプルの数
            - デフォルトは 200
        - `hazelcast.heartbeat.phiaccrual.failuredetector.min.std.dev.millis`
            - phi を計算するときに使用する正規分布の標準偏差の最小値
            - 小さい値を設定すると、結果が過敏になる
    - Ping Failure Detector
        - Deadline と Phi の追加設定として利用する
        - OSI の３層（ネットワーク層）で動作する
        - ハードウェアや他のローレベルなレイヤでの、より高速で決定的な検出ができる
        - この検出器は、メンバーが他の検出器によって疑われたあとに、他の検証を行うために設定される
        - もしくは、並行的にも動作する
        - ハードウェアやネットワークレベルの問題をより高速に検出する
        - `InetAddress.isReachable()` がベースになっている
        - ICMP のエコーを利用している
        - JVM が生のソケットを作成できる権限を持つ必要がある
        - もし権限がない場合は、 port 7 番を利用した TCP エコーに切り替わる
            - このへんの話は、 `isReachable()` の話
            - https://docs.oracle.com/javase/jp/10/docs/api/java/net/InetAddress.html#isReachable(int)
        - TCP 接続の代替手段は重くなるので、あまり推奨はされない
        - ICMP エコーのみを利用するための条件
            - なんか結構たいへんそう・・・

## 6. Rolling Member Upgrades
- アップグレードの方法
- エンタープライズ版だけの機能

## 7. Distributed Data Structures
### 7.1. Overview of Hazelcast Distributed Objects
- 分散データ構造には、パーティション戦略により、２つの種類がある
    - 分散化データ構造（partitioned data structures）
        - 異なるパーティションに保存される
        - Map, MultiMap, Cache, Event Journal
    - 非分散化データ構想（non-partitioned data structures）
        - 全てのインスタンスで、単一のパーティションに保存される
        - Queue, Set, List, Ringbuffer, Lock, ISemaphore, IAtomicLong, IAtomicReference, FlakeIdGenerator, ICountdownLatch, Cardinality Estimator, PN Counter
- また、複製 Map 構造 (Replicated Map structure) というものも提供している
- 分散オブジェクトのロードと削除
    - Hazelcast は、分散オブジェクトの get メソッドを大量に用意している
    - get メソッドを呼び出すと、オブジェクトがロードされる
    - 分散オブジェクトの設定は、指定がなければデフォルト値が使用される
    - 多くの分散オブジェクトは、遅延生成される
        - 最初にアクセスされたときに生成される
    - オブジェクトを削除するには、各分散オブジェクトが持つ `destroy` メソッドを使用する
        - 分散オブジェクトの中身がクリアされるだけで、その分散オブジェクトは引き続き利用できる
- パーティションの制御
    - 分散オブジェクトの名前は、どのパーティションに保存するかに利用される
    - 保存するパーティションを制御したい場合は、名前の後ろに `@` をつけて、続けてパーティションキーをつなげる
        - `instance.getMap("s1@foo");`
    - 分散オブジェクトには `getPartitionKey()` というメソッドがあるので、すでに登録した分散オブジェクトのキーを取得して、同じパーティションに新しい別の分散オブジェクトを入れるということもできる
        - パーティションキーは、 `@` で明示していなければ分散オブジェクトの名前がそのまま設定されている
        - `@` でキーを指定すると、そのキーが設定されることになる
    - `HazelcastInstance.getPartitionService().getPartition(Object)` で、対象のパーティションを取得できる
        - 引数にはパーティションキーを渡す
- 全てのデータ構造に共通な機能
    - メンバーがダウンしたら、バックアップレプリカのデータは、所有権とロックの情報を含め、動的に残りのメンバーに再分配される
    - 結果、データが失われることはない
    - 単一障害点となるクラスタのマスターは存在しない
    - クラスタ内の全てのメンバーは同じ権限と責任を持つ
    - 優遇されるメンバーは１つも存在しない
    - サーバーやマスターのような、外部に依存するようなものはない

### 7.2. Map
- `IMap extends ConcurrentMap`
- エントリを分けて、メンバーに均等に割り振る
- 各メンバーは、およそ「Map のエントリ数 * 2 * 1/n」のエントリーを持つことになる
    - n はクラスタ内のメンバーの数
    - ※２を掛けている理由がよくわからん
- キーがローカルやリモートの JVM 上でロックされる可能性があるが、全てのメソッドは正常に完了して戻ってくる
    - `ConcurrentMap` の処理は、決して `ConcurrentModificationException` をスローしない
    - ここでのロックは、多分、 `getLock()` のことを指している気がする
- 各エントリーのバックアップは、デフォルトでは１つだけ作成される
    - オーナーのパーティションにあるエントリと、他のどれかのメンバーのバックアップパーティションに１つだけコピーされる
    - バックアップの数は設定で変更可能
        - `map.backup-count`
        - 2 を指定すれば、２つのメンバーにコピーが分配される
        - 0 を指定すれば、バックアップは作成されない
        - パフォーマンスが重要であれば、最大は 6 になる（それ以上はパフォーマンスが悪くなるということか？）
    - バックアップには同期と非同期の２つがある
        - デフォルトでは、同期的に処理される
        - 同期の場合、バックアップ処理が完了するまでブロックされる
        - 当然、ブロッキングのコストは発生する
    - 非同期のバックアップ
        - ブロックせずにバックアップが行われる
        - バックアップは別のタイミングで行われる
        - 設定は、 `map.async-backup-count`
            - 数値を設定する
            - `map.backup-count` の方は `0` にしておく
    - バックアップを読む
        - デフォルトでは、常に key のオーナーから値を読み取る
            - 値の一貫性を保持するため
        - しかし、同じデータがバックアップとして自ノード内に存在するかもしれない
        - `read-backup-data` を `true` にすると、ローカルのバックアップから読み取ることができるようになる
            - デフォルトは `false`
        - パフォーマンスは向上するが、古いデータを読み取る可能性が生まれるようになる
        - 最低１つの同期バックアップか、非同期バックアップの場合に有効
            - 同期バックアップなら、バックアップが完了するまでブロックされる
            - つまり、アクセスできるようになった時点でバックアップのデータはオーナーと一致している
            - 結果、バックアップからデータを読み取っても、データが古いということは起こらない、ということだと思う
            - ただ、「最低１つ」と「非同期バックアップの場合」というのがよくわからない
        - バックアップからデータを読み取った場合、オーナーのデータに対するヒットには影響を与えない
            - キャッシュの有効期限的な話だと思う
            - つまり、バックアップからデータを読み取っていも、オーナー側のデータにアクセスしたことにはならないので、キャッシュが時間切れになるかもしれない、ということだと思う
    - Map Eviction
        - 3.7 からの機能
        - LRU (Least Recently Used)
        - LFU (Least Frequently Used)
        - partition-maximum-size がオーバーしたら eviction が起動する
            - parition-maximum-size = max-size * member-count / parition-count
                - max-size : Map に設定する値
                - Map 内のエントリ数の最大？
            - parition-maximum-size は、 partition ごとの最大数で、 max-size は Map 全体での最大数か？
        - max-size を超えると、あふれた１つ削除される
    - メモリ内のフォーマット
        - デフォルトはバイナリ(シリアライズ)で保存する
        - ローカルで処理する場合は、オブジェクト形式のほうが効率的な場合もある
        - バイナリ形式
            - シリアライズされたデータで保存する
            - key, value 両方が保存される
        - オブジェクト形式
            - デシリアライズされた形式で保存される
            - Map への投入や問い合わせが頻発し、オブジェクトが複雑でシリアライズにコストがかかる場合に有効
            - ただし、この場合でも key はバイナリで保存されている
        - ネイティブ形式
            - Enterprise でのみ使用可能
            - バイナリ形式なのは同じだが、保存先がヒープ外のメモリになる
        - get メソッドの速度
            - オブジェクト形式を指定した場合、 get で取得するオブジェクトはオリジナルインスタンスのクローンになる
            - オブジェクト形式の場合、オーナーインスタンスで一旦シリアライズされてから、メンバーインスタンスでデシリアライズして取得される
            - バイナリの場合は、シリアライズは済んでいるので、デシリアライズのみが必要になる
            - したがって、バイナリ形式のほうがはやい
        - put メソッドの速度
            - こちらも、バイナリ形式のほうがデシリアライズのみが必要になるので、オブジェクト形式よりは高速
        - オブジェクト形式の場合、ストアされているオブジェクトを取得して状態を変更しても、ストアされているオブジェクトには影響を与えない
            - クローンを返しているため

### 7.3. Queue
### 7.4. MultiMap
### 7.5. Set
### 7.6. List
### 7.7. Ringbuffer
### 7.8. Topic
### 7.9. Reliable Topic
### 7.10. Lock
### 7.11. IAtomicLong
### 7.12. ISemaphore
### 7.13. IAtomicReference
### 7.14. ICountDownLatch
### 7.15. PN Counter
### 7.16. IdGenerator
### 7.17. FlakeIdGenerator
### 7.18. Replicated Map
### 7.19. Cardinality Estimator Service
### 7.20. Event Journal
